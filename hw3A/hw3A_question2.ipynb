{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import codecs\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading t10k-images-idx3-ubyte\n",
      "Reading t10k-labels-idx1-ubyte\n",
      "Reading train-images-idx3-ubyte\n",
      "Reading train-labels-idx1-ubyte\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "path_to_data = os.environ.get(\"MNIST_DATAPATH\")\n",
    "mnist_files = os.listdir(path_to_data)\n",
    "mnist_files = [x for x in mnist_files if x.endswith(\"ubyte\")]\n",
    "\n",
    "\n",
    "def convert_to_int(byte):\n",
    "    integer = int(codecs.encode(byte, 'hex'), 16)\n",
    "    return integer\n",
    "\n",
    "\n",
    "dataset = {}\n",
    "for file in mnist_files:\n",
    "    print(\"Reading\", file)\n",
    "    with open(path_to_data + file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "        type_of_data = convert_to_int(data[:4])\n",
    "        length = convert_to_int(data[4:8])\n",
    "        if type_of_data == 2051:\n",
    "            category = \"images\"\n",
    "            number_of_rows = convert_to_int(data[8:12])\n",
    "            number_of_columns = convert_to_int(data[12:16])\n",
    "            parsed = np.frombuffer(data, dtype=np.uint8, offset=16)\n",
    "            parsed = parsed.reshape(length, number_of_rows, number_of_columns)\n",
    "        if type_of_data == 2049:\n",
    "            category = \"labels\"\n",
    "            parsed = np.frombuffer(data, dtype=np.uint8, offset=8)\n",
    "            parsed = parsed.reshape(length)\n",
    "        if length == 60000:\n",
    "            set = \"train\"\n",
    "        if length == 10000:\n",
    "            set = \"test\"\n",
    "        dataset[set + '_' + category] = parsed\n",
    "\n",
    "print(dataset[\"train_images\"][0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = dataset['train_images']\n",
    "train_labels = dataset['train_labels']\n",
    "train_images_flattened = train_images.reshape(60000, -1)\n",
    "train_images_flattened = train_images_flattened / 255\n",
    "\n",
    "test_images = dataset['test_images']\n",
    "test_labels = dataset['test_labels']\n",
    "test_images_flattened = test_images.reshape(10000, -1)\n",
    "test_images_flattened = test_images_flattened / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: train - (60000, 784), test - (10000, 784)\n",
      "PCA_5 shape: train - (60000, 5), test - (10000, 5)\n",
      "PCA_20 shape: train - (60000, 20), test - (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "scaler =  StandardScaler()\n",
    "mnist_features_train = scaler.fit_transform(train_images_flattened)\n",
    "mnist_features_test = scaler.transform(test_images_flattened)\n",
    "\n",
    "pca_5 = PCA(n_components=5)\n",
    "mnist_features_train_pca5 = pca_5.fit_transform(mnist_features_train)\n",
    "mnist_features_test_pca5 = pca_5.transform(mnist_features_test)\n",
    "\n",
    "pca_20 = PCA(n_components=20)\n",
    "mnist_features_train_pca20 = pca_20.fit_transform(mnist_features_train)\n",
    "mnist_features_test_pca20 = pca_20.transform(mnist_features_test)\n",
    "\n",
    "print(f\"Original Shape: train - {mnist_features_train.shape}, test - {mnist_features_test.shape}\\nPCA_5 shape: train - {mnist_features_train_pca5.shape}, test - {mnist_features_test_pca5.shape}\\nPCA_20 shape: train - {mnist_features_train_pca20.shape}, test - {mnist_features_test_pca20.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA D = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajeyk/neu_uml_workspace/chatbot_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy with PCA (D=5): 0.6800\n"
     ]
    }
   ],
   "source": [
    "log_reg_pca5 = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000, multi_class='multinomial')\n",
    "log_reg_pca5.fit(mnist_features_train_pca5, train_labels)\n",
    "y_pred_pca5 = log_reg_pca5.predict(mnist_features_test_pca5)\n",
    "\n",
    "acc_pca5 = accuracy_score(test_labels, y_pred_pca5)\n",
    "print(f'Logistic Regression Accuracy with PCA (D=5): {acc_pca5:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA D = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajeyk/neu_uml_workspace/chatbot_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy with PCA (D=20): 0.8721\n"
     ]
    }
   ],
   "source": [
    "log_reg_pca20 = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000, multi_class='multinomial')\n",
    "log_reg_pca20.fit(mnist_features_train_pca20, train_labels)\n",
    "y_pred_pca20 = log_reg_pca20.predict(mnist_features_test_pca20)\n",
    "\n",
    "acc_pca20 = accuracy_score(test_labels, y_pred_pca20)\n",
    "print(f'Logistic Regression Accuracy with PCA (D=20): {acc_pca20:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA D = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy with PCA (D=5): 0.6943\n"
     ]
    }
   ],
   "source": [
    "dt_pca5 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt_pca5.fit(mnist_features_train_pca5, train_labels)\n",
    "y_pred_dt_pca5 = dt_pca5.predict(mnist_features_test_pca5)\n",
    "\n",
    "acc_dt_pca5 = accuracy_score(test_labels, y_pred_dt_pca5)\n",
    "print(f'Decision Tree Accuracy with PCA (D=5): {acc_dt_pca5:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA D = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy with PCA (D=20): 0.8027\n"
     ]
    }
   ],
   "source": [
    "dt_pca20 = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "dt_pca20.fit(mnist_features_train_pca20, train_labels)\n",
    "y_pred_dt_pca20 = dt_pca20.predict(mnist_features_test_pca20)\n",
    "\n",
    "acc_dt_pca20 = accuracy_score(test_labels, y_pred_dt_pca20)\n",
    "print(f'Decision Tree Accuracy with PCA (D=20): {acc_dt_pca20:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy with PCA (D=5): 0.6800\n",
      "Logistic Regression Accuracy with PCA (D=20): 0.8721\n",
      "Decision Tree Accuracy with PCA (D=5): 0.6943\n",
      "Decision Tree Accuracy with PCA (D=20): 0.8027\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Accuracy with PCA (D=5): {acc_pca5:.4f}')\n",
    "print(f'Logistic Regression Accuracy with PCA (D=20): {acc_pca20:.4f}')\n",
    "print(f'Decision Tree Accuracy with PCA (D=5): {acc_dt_pca5:.4f}')\n",
    "print(f'Decision Tree Accuracy with PCA (D=20): {acc_dt_pca20:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spambase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 4601\n",
      "Label distribution: class\n",
      "0    2788\n",
      "1    1813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "spambase = fetch_openml(name=\"Spambase\", version=1, parser=\"pandas\")\n",
    "features_sb = spambase.data\n",
    "labels_sb = spambase.target.astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {len(labels_sb)}\")\n",
    "print(\"Label distribution:\", labels_sb.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (3680, 57)\n",
      "Test set shape: (921, 57)\n"
     ]
    }
   ],
   "source": [
    "features_sb_train, features_sb_test, labels_sb_train, labels_sb_test = train_test_split(features_sb, labels_sb, test_size=0.2, random_state=97)\n",
    "print(f\"Training set shape: {features_sb_train.shape}\")\n",
    "print(f\"Test set shape: {features_sb_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: 0.38877770578183435\n"
     ]
    }
   ],
   "source": [
    "scaler_sb = StandardScaler()\n",
    "spambase_features_train = scaler_sb.fit_transform(features_sb_train)\n",
    "spambase_features_test = scaler_sb.transform(features_sb_test)\n",
    "\n",
    "pca_10 = PCA(n_components=10)\n",
    "spambase_features_train_pca10 = pca_10.fit_transform(spambase_features_train)\n",
    "spambase_features_test_pca10 = pca_10.transform(spambase_features_test)\n",
    "\n",
    "print(\"Explained Variance Ratio:\", sum(pca_10.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy with PCA (D=10) on Spambase: 0.8936\n"
     ]
    }
   ],
   "source": [
    "log_reg_spam_pca10 = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000)\n",
    "log_reg_spam_pca10.fit(spambase_features_train_pca10, labels_sb_train)\n",
    "y_pred_spam_pca = log_reg_spam_pca10.predict(spambase_features_test_pca10)\n",
    "\n",
    "acc_spam_pca = accuracy_score(labels_sb_test, y_pred_spam_pca)\n",
    "print(f'Logistic Regression Accuracy with PCA (D=10) on Spambase: {acc_spam_pca:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA (D=1): Accuracy = 0.8284\n",
      "PCA (D=4): Accuracy = 0.8730\n",
      "PCA (D=7): Accuracy = 0.8708\n",
      "PCA (D=10): Accuracy = 0.8936\n",
      "Smallest D for comparable accuracy: 10\n"
     ]
    }
   ],
   "source": [
    "original_spam_acc = 0.9121\n",
    "\n",
    "for d in range(1, 51, 3):  # Try PCA from D=5 to D=50\n",
    "    pca_d = PCA(n_components=d)\n",
    "    X_train_spam_pca_d = pca_d.fit_transform(spambase_features_train)\n",
    "    X_test_spam_pca_d = pca_d.transform(spambase_features_test)\n",
    "\n",
    "    log_reg_spam_pca_d = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", max_iter=1000)\n",
    "    log_reg_spam_pca_d.fit(X_train_spam_pca_d, labels_sb_train)\n",
    "    y_pred_spam_pca = log_reg_spam_pca_d.predict(X_test_spam_pca_d)\n",
    "\n",
    "    acc_pca_d = accuracy_score(labels_sb_test, y_pred_spam_pca)\n",
    "    print(f'PCA (D={d}): Accuracy = {acc_pca_d:.4f}')\n",
    "    \n",
    "    if acc_pca_d >= original_spam_acc - 0.02 and acc_pca_d <= original_spam_acc + 0.02:  # Stop if comparable accuracy is reached\n",
    "        print(f\"Smallest D for comparable accuracy: {d}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
